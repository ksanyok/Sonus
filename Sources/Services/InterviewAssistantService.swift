import Foundation
import AVFoundation

/// –°–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω–æ–º –∏–Ω—Ç–µ—Ä–≤—å—é:
/// - –†–µ–∞–ª-—Ç–∞–π–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ä–µ—á–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞
/// - –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
/// - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ—Å–ª–µ –ø–∞—É–∑/–≤–æ–ø—Ä–æ—Å–æ–≤
final class InterviewAssistantService: ObservableObject {
    static let shared = InterviewAssistantService()
    
    @Published var isActive = false
    @Published var currentEnglishText = ""
    @Published var currentRussianTranslation = ""
    @Published var suggestedResponse = ""
    @Published var confidenceLevel: Double = 0
    @Published var dialogueHistory: [DialogueEntry] = []
    
    // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å)
    var pauseThreshold: TimeInterval = 2.5 // –°–µ–∫—É–Ω–¥ –ø–∞—É–∑—ã –ø–µ—Ä–µ–¥ –ø–æ–¥—Å–∫–∞–∑–∫–æ–π
    var chunkProcessingInterval: TimeInterval = 4.0 // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —á–∞–Ω–∫–æ–≤
    
    struct DialogueEntry: Identifiable, Equatable {
        let id = UUID()
        let timestamp: Date
        let speaker: Speaker
        let englishText: String
        let russianTranslation: String
        
        enum Speaker {
            case interviewer // –°–æ–±–µ—Å–µ–¥–Ω–∏–∫
            case user // –í—ã
        }
    }
    
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä AudioRecorder –¥–ª—è Interview Assistant
    private let audioRecorder = AudioRecorder()
    private let openAI = OpenAIClient.shared
    
    private var conversationContext: [String] = []
    private var transcriptionTask: Task<Void, Never>?
    private var lastChunkProcessedAt = Date.distantPast
    private var accumulatedTranscript = ""
    private var fullRecordingFilename: String?
    
    private var lastSpeechTime = Date()
    private var hintCheckTimer: Timer?
    private var lastProcessedText = "" // –î–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    
    private init() {}
    
    /// –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ–º–æ—â–Ω–∏–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
    @MainActor
    func start() async throws {
        guard !isActive else { return }
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        if !audioRecorder.isPermissionGranted {
            let granted = await audioRecorder.requestPermission()
            guard granted else {
                throw InterviewAssistantError.microphonePermissionDenied
            }
        }
        
        // –û—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        currentEnglishText = ""
        currentRussianTranslation = ""
        suggestedResponse = ""
        conversationContext.removeAll()
        accumulatedTranscript = ""
        dialogueHistory.removeAll()
        lastSpeechTime = Date()
        lastProcessedText = ""
        fullRecordingFilename = nil
        
        // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —á–∞–Ω–∫–æ–≤
        audioRecorder.onChunkReady = { [weak self] chunkURL in
            self?.processAudioChunk(chunkURL)
        }
        
        // –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        do {
            audioRecorder.warmUpEngineIfPossible()
            let filename = try audioRecorder.startRecording()
            fullRecordingFilename = filename
            
            isActive = true
            
            // –ó–∞–ø—É—Å–∫ —Ç–∞–π–º–µ—Ä–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—É–∑
            startHintCheckTimer()
            
            print("‚úÖ Interview Assistant —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
        } catch {
            // –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –æ—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            audioRecorder.onChunkReady = nil
            isActive = false
            throw error
        }
    }
    
    /// –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ–º–æ—â–Ω–∏–∫–∞
    @MainActor
    func stop() async -> (filename: String, duration: TimeInterval, transcript: String)? {
        guard isActive else { return nil }
        
        audioRecorder.onChunkReady = nil
        let recordingResult = audioRecorder.stopRecording()
        
        hintCheckTimer?.invalidate()
        hintCheckTimer = nil
        transcriptionTask?.cancel()
        transcriptionTask = nil
        
        isActive = false
        
        // –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        let fullTranscript = dialogueHistory.map { entry in
            let speaker = entry.speaker == .interviewer ? "Interviewer" : "You"
            return "[\(speaker)]: \(entry.englishText)\n[Translation]: \(entry.russianTranslation)"
        }.joined(separator: "\n\n")
        
        print("‚èπ Interview Assistant —Ä–µ–∂–∏–º –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        if let result = recordingResult {
            return (filename: result.filename, duration: result.duration, transcript: fullTranscript)
        }
        return nil
    }
    
    private func startHintCheckTimer() {
        DispatchQueue.main.async { [weak self] in
            self?.hintCheckTimer?.invalidate()
            self?.hintCheckTimer = Timer.scheduledTimer(withTimeInterval: 0.5, repeats: true) { [weak self] _ in
                self?.checkForPauseAndGenerateHint()
            }
        }
    }
    
    private func checkForPauseAndGenerateHint() {
        let timeSinceLastSpeech = Date().timeIntervalSince(lastSpeechTime)
        
        // –ï—Å–ª–∏ –ø—Ä–æ—à–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏ –∏ –µ—Å—Ç—å –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        guard timeSinceLastSpeech >= pauseThreshold,
              !accumulatedTranscript.isEmpty,
              !currentEnglishText.isEmpty else {
            return
        }
        
        // –°–±—Ä–æ—Å–∏–º —Ç–∞–π–º–µ—Ä —á—Ç–æ–±—ã –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ
        lastSpeechTime = Date()
        
        // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Å–∫–∞–∑–∫–∏
        Task {
            await generateResponseHint()
        }
    }
    
    private func processAudioChunk(_ chunkURL: URL) {
        // –ò–∑–±–µ–≥–∞–µ–º –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–µ —á–∞—â–µ —Ä–∞–∑–∞ –≤ N —Å–µ–∫—É–Ω–¥
        let now = Date()
        guard now.timeIntervalSince(lastChunkProcessedAt) >= chunkProcessingInterval else {
            return
        }
        lastChunkProcessedAt = now
        
        transcriptionTask?.cancel()
        transcriptionTask = Task { [weak self] in
            await self?.transcribeAndTranslateChunk(chunkURL)
        }
    }
    
    private func transcribeAndTranslateChunk(_ chunkURL: URL) async {
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞ - –æ—Ç—Å–µ–∫–∞–µ–º —Ç–∏—à–∏–Ω—É/—Ñ–æ–Ω
        guard audioRecorder.hasSignificantAudio(at: chunkURL, threshold: 0.015) else {
            print("‚è© –ß–∞–Ω–∫ –ø—Ä–æ–ø—É—â–µ–Ω: —Å–ª–∏—à–∫–æ–º —Ç–∏—Ö–æ –∏–ª–∏ —Ç–æ–ª—å–∫–æ —Ñ–æ–Ω")
            try? FileManager.default.removeItem(at: chunkURL)
            return
        }
        
        do {
            // 1. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —á–∞–Ω–∫–∞
            let englishText = try await openAI.transcribe(audioURL: chunkURL)
            
            // –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            let cleaned = englishText.trimmingCharacters(in: .whitespacesAndNewlines)
            guard !cleaned.isEmpty, cleaned.count > 3 else {
                print("‚è© –ß–∞–Ω–∫ –ø—Ä–æ–ø—É—â–µ–Ω: –ø—É—Å—Ç–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç")
                try? FileManager.default.removeItem(at: chunkURL)
                return
            }
            
            print("‚úÖ –†–µ–∞–ª—å–Ω–∞—è —Ä–µ—á—å: \(cleaned)")
            
            print("‚úÖ –†–µ–∞–ª—å–Ω–∞—è —Ä–µ—á—å: \(cleaned)")
            
            // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏
            lastSpeechTime = Date()
            
            // 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç (–±–∞–∑–æ–≤–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
            let speaker: DialogueEntry.Speaker = determineSpeaker(cleaned)
            
            // 3. –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
            let russianTranslation = try await translateToRussian(cleaned)
            
            // 4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ UI
            await MainActor.run { [weak self] in
                guard let self = self else { return }
                
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç
                if self.lastProcessedText == cleaned {
                    return
                }
                self.lastProcessedText = cleaned
                
                self.currentEnglishText = cleaned
                self.currentRussianTranslation = russianTranslation
                
                // –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
                let entry = DialogueEntry(
                    timestamp: Date(),
                    speaker: speaker,
                    englishText: cleaned,
                    russianTranslation: russianTranslation
                )
                self.dialogueHistory.append(entry)
                
                // –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ —Ä–µ–ø–ª–∏–∫ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ –¥–ª—è –ø–æ–¥—Å–∫–∞–∑–æ–∫
                if speaker == .interviewer {
                    self.conversationContext.append("Interviewer: \(englishText)\nTranslation: \(russianTranslation)")
                    if self.conversationContext.count > 8 {
                        self.conversationContext.removeFirst()
                    }
                }
                
                self.accumulatedTranscript += "\n[\(speaker == .interviewer ? "Interviewer" : "You")]: \(englishText)"
            }
            
            print("üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–æ: \(englishText)")
            print("üîÑ –ü–µ—Ä–µ–≤–æ–¥: \(russianTranslation)")
            
            // –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            try? FileManager.default.removeItem(at: chunkURL)
            
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞: \(error.localizedDescription)")
        }
    }
    
    private func translateToRussian(_ englishText: String) async throws -> String {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
        let prompt = """
        –ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π. 
        –≠—Ç–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è/–∏–Ω—Ç–µ—Ä–≤—å—é, –ø–µ—Ä–µ–≤–æ–¥–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ.
        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
        
        –¢–µ–∫—Å—Ç: \(englishText)
        """
        
        let response = try await openAI.chatCompletion(
            messages: [
                ["role": "system", "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π."],
                ["role": "user", "content": prompt]
            ],
            temperature: 0.3
        )
        
        return response
    }
    
    @MainActor
    private func generateResponseHint() async {
        guard !conversationContext.isEmpty else { return }
        
        do {
            // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–ø–ª–∏–∫
            let contextText = conversationContext.suffix(5).joined(separator: "\n\n")
            
            let prompt = """
            –¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —á–µ–ª–æ–≤–µ–∫—É –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.
            –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π):
            
            \(contextText)
            
            –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å/–≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞:
            \(currentEnglishText)
            
            –ü—Ä–µ–¥–ª–æ–∂–∏ –∫—Ä–∞—Ç–∫–∏–π –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.
            –¢–∞–∫–∂–µ –æ—Ü–µ–Ω–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–∞ –æ—Ç 0 –¥–æ 1 (0 = –ø—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å, 1 = —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å).
            
            –í–µ—Ä–Ω–∏ JSON —Ñ–æ—Ä–º–∞—Ç–∞:
            {
              "suggested_response": "–∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
              "confidence": 0.0-1.0
            }
            """
            
            let jsonResponse = try await openAI.chatCompletionJSON(
                messages: [
                    ["role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –í–æ–∑–≤—Ä–∞—â–∞–π —Ç–æ–ª—å–∫–æ JSON."],
                    ["role": "user", "content": prompt]
                ],
                temperature: 0.6
            )
            
            if let data = jsonResponse.data(using: .utf8),
               let decoded = try? JSONDecoder().decode(HintResponse.self, from: data) {
                await MainActor.run {
                    self.suggestedResponse = decoded.suggested_response
                    self.confidenceLevel = 1.0 - decoded.confidence // –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                }
                
                print("üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞: \(decoded.suggested_response)")
            }
            
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏: \(error.localizedDescription)")
        }
    }
    
    /// –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç
    /// –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é –∞–Ω–∞–ª–∏–∑–∞ –≥–æ–ª–æ—Å–∞ –∏–ª–∏ ML
    private func determineSpeaker(_ text: String) -> DialogueEntry.Speaker {
        // –ï—Å–ª–∏ –ø–æ—Å–ª–µ –Ω–∞—à–µ–π –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø—Ä–æ—à–ª–æ –º–∞–ª–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≥–æ–≤–æ—Ä–∏–º –º—ã
        let timeSinceSuggestion = Date().timeIntervalSince(lastSpeechTime)
        
        // –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∞ –±—ã–ª–∞ –Ω–µ–¥–∞–≤–Ω–æ (< 10 —Å–µ–∫) –∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –º—ã
        if !suggestedResponse.isEmpty && timeSinceSuggestion < 10 {
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å —Å –ø–æ–¥—Å–∫–∞–∑–∫–æ–π
            let suggestionWords = Set(suggestedResponse.lowercased().split(separator: " ").map(String.init))
            let textWords = Set(text.lowercased().split(separator: " ").map(String.init))
            let commonWords = suggestionWords.intersection(textWords)
            
            // –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±—â–∏–µ —Å–ª–æ–≤–∞ –∏ —Ç–µ–∫—Å—Ç –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –º—ã –æ—Ç–≤–µ—á–∞–µ–º
            if commonWords.count >= 2 && text.split(separator: " ").count < 30 {
                return .user
            }
        }
        
        // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ (–∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä)
        // TODO: –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≥–æ–ª–æ—Å–∞ –∏–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ä–µ—á–∏
        return .interviewer
    }
    
    struct HintResponse: Codable {
        let suggested_response: String
        let confidence: Double
    }
}

enum InterviewAssistantError: Error, LocalizedError {
    case microphonePermissionDenied
    case transcriptionFailed
    case translationFailed
    
    var errorDescription: String? {
        switch self {
        case .microphonePermissionDenied:
            return "–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â–µ–Ω"
        case .transcriptionFailed:
            return "–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏"
        case .translationFailed:
            return "–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞"
        }
    }
}
