import Foundation
import AVFoundation
import Combine

/// –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ª—é–±—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
/// - –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–∞ –ª—é–±–æ–º —è–∑—ã–∫–µ
/// - –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π —è–∑—ã–∫
/// - –ê–Ω–∞–ª–∏–∑ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞
/// - –ü–æ–¥—Å–∫–∞–∑–∫–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
final class RealTimeAssistantService: ObservableObject {
    static let shared = RealTimeAssistantService()
    
    @Published var isActive = false
    @Published var currentTranscript = ""
    @Published var translation = ""
    @Published var suggestion = ""
    @Published var engagement = EngagementLevel.neutral
    @Published var engagementScore: Double = 0.5 // 0.0 - 1.0
    @Published var conversationHistory: [ConversationEntry] = []
    
    // –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    var targetLanguage: AssistantLanguage = .russian
    var assistantMode: AssistantMode = .translation
    var autoSuggest = true
    var pauseThreshold: TimeInterval = 2.0
    
    enum AssistantLanguage: String, CaseIterable, Identifiable {
        case russian = "ru"
        case english = "en"
        case ukrainian = "uk"
        case german = "de"
        case french = "fr"
        case spanish = "es"
        
        var id: String { rawValue }
        
        var displayName: String {
            switch self {
            case .russian: return "–†—É—Å—Å–∫–∏–π"
            case .english: return "English"
            case .ukrainian: return "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"
            case .german: return "Deutsch"
            case .french: return "Fran√ßais"
            case .spanish: return "Espa√±ol"
            }
        }
    }
    
    enum AssistantMode: String, CaseIterable, Identifiable {
        case translation = "translation"
        case coaching = "coaching"
        case notes = "notes"
        
        var id: String { rawValue }
        
        var displayName: String {
            switch self {
            case .translation: return "–ü–µ—Ä–µ–≤–æ–¥ –∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏"
            case .coaching: return "–ö–æ—É—á–∏–Ω–≥ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
            case .notes: return "–ó–∞–º–µ—Ç–∫–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã"
            }
        }
        
        var icon: String {
            switch self {
            case .translation: return "translate"
            case .coaching: return "person.fill.checkmark"
            case .notes: return "note.text"
            }
        }
    }
    
    enum EngagementLevel {
        case high      // 0.7 - 1.0
        case neutral   // 0.4 - 0.7
        case low       // 0.0 - 0.4
        
        var color: String {
            switch self {
            case .high: return "green"
            case .neutral: return "yellow"
            case .low: return "red"
            }
        }
        
        var emoji: String {
            switch self {
            case .high: return "üòä"
            case .neutral: return "üòê"
            case .low: return "üòü"
            }
        }
        
        var description: String {
            switch self {
            case .high: return "–í—ã—Å–æ–∫–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å"
            case .neutral: return "–ù–æ—Ä–º–∞–ª—å–Ω–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å"
            case .low: return "–ù–∏–∑–∫–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å"
            }
        }
    }
    
    struct ConversationEntry: Identifiable, Equatable {
        let id = UUID()
        let timestamp: Date
        let originalText: String
        let translatedText: String
        let detectedLanguage: String
        let engagementScore: Double
    }
    
    private let audioRecorder = AudioRecorder()
    private let openAI = OpenAIClient.shared
    private var lastChunkProcessedAt = Date.distantPast
    private var fullRecordingFilename: String?
    private var chunkProcessingTask: Task<Void, Never>?
    
    // –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç–∏
    private var recentTranscripts: [String] = []
    private var lastEngagementCheck = Date()
    private var sentimentHistory: [Double] = []
    
    private init() {
        // –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        loadSettings()
    }
    
    // MARK: - Public Methods
    
    @MainActor
    func start() async throws {
        guard !isActive else { return }
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
        if !audioRecorder.isPermissionGranted {
            let granted = await audioRecorder.requestPermission()
            guard granted else {
                throw AssistantError.microphonePermissionDenied
            }
        }
        
        // –û—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        currentTranscript = ""
        translation = ""
        suggestion = ""
        conversationHistory.removeAll()
        recentTranscripts.removeAll()
        sentimentHistory.removeAll()
        engagementScore = 0.5
        engagement = .neutral
        
        // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —á–∞–Ω–∫–æ–≤
        audioRecorder.onChunkReady = { [weak self] chunkURL in
            self?.processAudioChunk(chunkURL)
        }
        
        // –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏
        do {
            audioRecorder.warmUpEngineIfPossible()
            let filename = try audioRecorder.startRecording()
            fullRecordingFilename = filename
            isActive = true
            
            print("‚úÖ AI Assistant –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –≤ —Ä–µ–∂–∏–º–µ: \(assistantMode.displayName)")
            print("üìù –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫: \(targetLanguage.displayName)")
        } catch {
            audioRecorder.onChunkReady = nil
            isActive = false
            throw error
        }
    }
    
    @MainActor
    func stop() async -> (filename: String, duration: TimeInterval, transcript: String)? {
        guard isActive else { return nil }
        
        audioRecorder.onChunkReady = nil
        chunkProcessingTask?.cancel()
        
        guard let result = audioRecorder.stopRecording() else {
            isActive = false
            return nil
        }
        
        isActive = false
        
        // –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        let fullTranscript = conversationHistory.map { entry in
            "[\(formatTime(entry.timestamp))] \(entry.originalText)"
        }.joined(separator: "\n")
        
        print("‚úÖ AI Assistant –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return (result.filename, result.duration, fullTranscript)
    }
    
    func updateEngagement(_ score: Double) {
        engagementScore = max(0, min(1, score))
        
        engagement = if engagementScore >= 0.7 {
            .high
        } else if engagementScore >= 0.4 {
            .neutral
        } else {
            .low
        }
    }
    
    // MARK: - Private Methods
    
    private func processAudioChunk(_ chunkURL: URL) {
        // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —á–∞–Ω–∫–æ–≤
        let now = Date()
        guard now.timeIntervalSince(lastChunkProcessedAt) >= 3.0 else { return }
        lastChunkProcessedAt = now
        
        chunkProcessingTask = Task { [weak self] in
            guard let self = self else { return }
            
            do {
                // 1. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                let transcript = try await self.openAI.transcribe(audioURL: chunkURL)
                
                guard !transcript.isEmpty, !Task.isCancelled else { return }
                
                // 2. –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫
                let translated = try await self.translateText(transcript)
                
                guard !Task.isCancelled else { return }
                
                await MainActor.run {
                    self.currentTranscript = transcript
                    self.translation = translated
                    
                    // –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                    let entry = ConversationEntry(
                        timestamp: Date(),
                        originalText: transcript,
                        translatedText: translated,
                        detectedLanguage: "auto",
                        engagementScore: self.engagementScore
                    )
                    self.conversationHistory.append(entry)
                    
                    // –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    self.recentTranscripts.append(transcript)
                    if self.recentTranscripts.count > 5 {
                        self.recentTranscripts.removeFirst()
                    }
                }
                
                // 3. –ê–Ω–∞–ª–∏–∑ –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç–∏
                if now.timeIntervalSince(self.lastEngagementCheck) >= 5.0 {
                    await self.analyzeEngagement(transcript: transcript)
                    self.lastEngagementCheck = now
                }
                
                // 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Å–∫–∞–∑–∫–∏
                if self.autoSuggest {
                    try await self.generateSuggestion(transcript: transcript, translation: translated)
                }
                
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞: \(error)")
            }
        }
    }
    
    private func translateText(_ text: String) async throws -> String {
        let prompt = """
        Translate the following text to \(targetLanguage.displayName).
        Keep it natural and conversational.
        Text: \(text)
        """
        
        let response = try await openAI.chatCompletion(messages: [
            ["role": "system", "content": "You are a professional translator. Provide only the translation, no explanations."],
            ["role": "user", "content": prompt]
        ])
        
        return response.trimmingCharacters(in: .whitespacesAndNewlines)
    }
    
    private func analyzeEngagement(transcript: String) async {
        let allText = recentTranscripts.joined(separator: " ")
        
        let prompt = """
        Analyze the engagement level of this conversation based on the transcript.
        Consider: enthusiasm, question frequency, response length, emotional tone.
        
        Recent conversation:
        \(allText)
        
        Return ONLY a number between 0.0 (low engagement) and 1.0 (high engagement).
        """
        
        do {
            let response = try await openAI.chatCompletion(messages: [
                ["role": "system", "content": "You are an expert in conversation analysis. Return only a decimal number."],
                ["role": "user", "content": prompt]
            ])
            
            if let score = Double(response.trimmingCharacters(in: .whitespacesAndNewlines)) {
                await MainActor.run {
                    self.updateEngagement(score)
                    self.sentimentHistory.append(score)
                    if self.sentimentHistory.count > 10 {
                        self.sentimentHistory.removeFirst()
                    }
                }
            }
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç–∏: \(error)")
        }
    }
    
    private func generateSuggestion(transcript: String, translation: String) async throws {
        let modeContext = switch assistantMode {
        case .translation:
            "Suggest how to respond naturally in the same language as the conversation."
        case .coaching:
            "Provide coaching advice on how to improve the conversation and maintain engagement."
        case .notes:
            "Extract and highlight key points and action items."
        }
        
        let engagementContext = if engagement == .low {
            "\n\nIMPORTANT: Engagement is LOW. Suggest ways to re-engage the person."
        } else {
            ""
        }
        
        let prompt = """
        Mode: \(assistantMode.displayName)
        Conversation: \(transcript)
        Translation: \(translation)
        \(modeContext)\(engagementContext)
        
        Provide a brief, actionable suggestion in Russian.
        """
        
        let response = try await openAI.chatCompletion(messages: [
            ["role": "system", "content": "You are a helpful conversation assistant."],
            ["role": "user", "content": prompt]
        ])
        
        await MainActor.run {
            self.suggestion = response.trimmingCharacters(in: .whitespacesAndNewlines)
        }
    }
    
    private func formatTime(_ date: Date) -> String {
        let formatter = DateFormatter()
        formatter.timeStyle = .medium
        return formatter.string(from: date)
    }
    
    // MARK: - Settings
    
    private func loadSettings() {
        if let langCode = UserDefaults.standard.string(forKey: "assistant.targetLanguage"),
           let lang = AssistantLanguage(rawValue: langCode) {
            targetLanguage = lang
        }
        
        if let modeCode = UserDefaults.standard.string(forKey: "assistant.mode"),
           let mode = AssistantMode(rawValue: modeCode) {
            assistantMode = mode
        }
        
        autoSuggest = UserDefaults.standard.object(forKey: "assistant.autoSuggest") as? Bool ?? true
    }
    
    func saveSettings() {
        UserDefaults.standard.set(targetLanguage.rawValue, forKey: "assistant.targetLanguage")
        UserDefaults.standard.set(assistantMode.rawValue, forKey: "assistant.mode")
        UserDefaults.standard.set(autoSuggest, forKey: "assistant.autoSuggest")
    }
}

enum AssistantError: LocalizedError {
    case microphonePermissionDenied
    
    var errorDescription: String? {
        switch self {
        case .microphonePermissionDenied:
            return "–ù–µ–æ–±—Ö–æ–¥–∏–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –¥–ª—è —Ä–∞–±–æ—Ç—ã AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"
        }
    }
}
